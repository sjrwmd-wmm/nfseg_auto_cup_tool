# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

# Please report errors and corrections to jwg (at) srwmd.org

'''
20200518   PMB      Reorganized the main program to be a called function
                    from the main python tool running the CUP process.
                    Added arguments to the function call to read from
                    preset definition file locations and write results
                    within the working results directory. Additionally,
                    some of the basic functions have been delegated
                    to the global utilities versions (e.g., unit conversions).
                    This required adding the PATH to these utilities.
                    Added a logfile that is also sent to the two classes.
                    
                    TODO: Simplify the whole script.
                          Add True/False to return of main
'''

# Import libraries
import os
import sys
sys.path.insert(0,'src\utilities')
import basic_utilities as bscut
import mydefinitions as mydef


class ContributingGages(object):
    """ Class for defining and working with relations between gaging stations
        and their upstream contributing gaging stations.
        
        20180725    original code   Trey Grubbs
    """
    
    def __init__(self):
        self.sim_fluxes = {}

    def initialize_output_files(self, output_summary_file_name):
        """ Open output files. """
        #output_summary_file_name = 'delta_q_summary.csv'
        output_summary_file_header = ('station_number,' +
                                      'station_name,' +
                                      'simulated_flux_base_condition_cfs,' +
                                      'simulated_flux_with_cup_cfs,' +
                                      'simulated_change_in_flow_cfs,' +
                                      'simulated_change_in_flow_as_fraction_of_flow,' +
                                      'simulated_change_in_flow_as_a_fraction_of_cup\n')
        self.output_summary_file = open(output_summary_file_name, 'w')
        self.output_summary_file.write(output_summary_file_header)

    def read_file_with_cup_id_and_amount(self, input_file_name):
        """ Parse a file containing one record and two-fields:
                cup id number
                withdrawal rate, in 
            Store the data in instance variables.
        """
        f = open(input_file_name, 'r')
        line_list = f.readline().rstrip().split(',')
        self.cup_id, self.cup_withdrawal_mgd = tuple(line_list)
        self.cup_withdrawal_mgd = float(self.cup_withdrawal_mgd)
        self.cup_withdrawal_cfs = self.cup_withdrawal_mgd * mydef.ConvFactors().mgd2cfs

    def parse_station_numbers_and_names_file(self, input_file_name):
        """ Parse a file containing two-fields: station number and station name.
            Store the data in a dictionary.
        """
        self.station_list = []
        self.station_names_and_reach_types = {}
        f = open(input_file_name, 'r')
        for line in f.readlines():
            line_list = line.rstrip().split(',')
            station_number, station_name, reach_type = tuple(line_list)
            self.station_list.append(station_number.lower())
            self.station_names_and_reach_types[(station_number, 'station_name')] = station_name.lower()
            self.station_names_and_reach_types[(station_number, 'reach_type')] = reach_type
        f.close()

    def parse_simualted_qr_file(self, input_file_name):
        """ Parse a file with simulated flux values for 'qr reaches'. Note that 
            this type of file is typically generated by a program like
            sim_q_reach_3d_auto.py.
        """
        field_indices = {}
        f = open(input_file_name, 'r')
        
        field_names = f.readline().rstrip().split()[1:]
        for field_name in field_names:
            index_value = field_names.index(field_name)
            field_indices[field_name] = index_value
            
        for line in f.readlines():
            line_list = line.rstrip().split()
            ds_station_number = line_list[0].lower()
            flux_tuple = [float(x) for x in line_list[1:]]
            flux_record_length = len(line_list)
            
            total_flux_sp1, total_flux_sp2, delta_total_flux_sp2_minus_sp1 = (
                flux_tuple[field_indices['total_sim_flux_sp1_ts1']],
                flux_tuple[field_indices['total_sim_flux_sp2_ts1']],
                flux_tuple[field_indices['del_total_sim_flux']]
                )
            self.sim_fluxes[(ds_station_number, 'total_sim_flux_sp1', 'qr')] = total_flux_sp1
            self.sim_fluxes[(ds_station_number, 'total_sim_flux_sp2', 'qr')] = total_flux_sp2
            self.sim_fluxes[(ds_station_number, 'delta_total_flux_sp2_minus_sp1', 'qr')] = delta_total_flux_sp2_minus_sp1

        f.close()

    def parse_simualted_qs_file(self, input_file_name):
        """ Parse a file with simulated flux values for 'qs reaches', which
            are river reaches that represent a collection of subreaches
            (i.e. 'qr' reaches). Note that 
            this type of file is typically generated by a program like
            sum_sim_q_reach.py.
        """
        field_indices = {}
        f = open(input_file_name, 'r')
        
        field_names = f.readline().strip().split(',')[2:]
        for field_name in field_names:
            index_value = field_names.index(field_name)
            field_indices[field_name] = index_value
            
        for line in f.readlines():
            line_list = line.rstrip().split(',')
            ds_station_number = line_list[0].lower()
            flux_tuple = [float(x) for x in line_list[2:]]
            flux_record_length = len(line_list)
            total_flux_sp1, total_flux_sp2, delta_total_flux_sp2_minus_sp1 = (
                flux_tuple[field_indices['total_sim_flux_sp1']],
                flux_tuple[field_indices['total_sim_flux_sp2']],
                flux_tuple[field_indices['total_sim_flux_sp2_minus_sp1']]
                )
            self.sim_fluxes[(ds_station_number, 'total_sim_flux_sp1', 'qs')] = total_flux_sp1
            self.sim_fluxes[(ds_station_number, 'total_sim_flux_sp2', 'qs')] = total_flux_sp2
            self.sim_fluxes[(ds_station_number, 'delta_total_flux_sp2_minus_sp1', 'qs')] = delta_total_flux_sp2_minus_sp1
            
        f.close()


    def output_station_fluxes(self):
        """ Output simulated fluxes and simulated flux differences for stations
            listed in file, station_namber_and_names.csv.
        """
        for station_number in self.station_list:
            if station_number == 2321500:
                pass
            self.output_simulated_flux_for_one_station(station_number)
    
    def output_simulated_flux_for_one_station(self, station_number):
        """ Output cumulative flux data for each station. """
        #output_record_detailed = self.create_output_string_detailed(station_number)
        output_record_summary = self.create_output_string_summary(station_number)
        self.output_summary_file.write(output_record_summary)

    def create_output_string_summary(self,station_number):
        """ Assemble output strings for a given station number. """
        station_name = self.station_names_and_reach_types[(station_number, 'station_name')]
        reach_type = self.station_names_and_reach_types[(station_number, 'reach_type')]
        output_string = '{0},{1},'.format(station_number, station_name)

        flux_sp1 = self.sim_fluxes[(station_number,'total_sim_flux_sp1', reach_type)]
        flux_sp2 = self.sim_fluxes[(station_number,'total_sim_flux_sp2', reach_type)]
        #flux_change = self.sim_fluxes[(station_number,'delta_total_flux_sp2_minus_sp1', reach_type)]
        flux_change = flux_sp2 - flux_sp1
        if abs(flux_sp1) > 1.e-10:
            flux_change_as_fraction_of_flow = flux_change/flux_sp1
        else:
            flux_change_as_fraction_of_flow = -1.2345e30
        flux_change_fraction_of_cup = flux_change/self.cup_withdrawal_cfs
        output_tuple_for_appending = (flux_sp1, flux_sp2, flux_change, flux_change_as_fraction_of_flow, flux_change_fraction_of_cup)
        output_list_for_joining = ['{0:0.6f}'.format(x) for x in output_tuple_for_appending]
        output_string_for_appending = ','.join(output_list_for_joining)
        output_string += (output_string_for_appending + '\n')
        return output_string

    def close_output_files(self):
        """ Close the output files. """
        self.output_summary_file.close()

def main(logfile,
         postproc_deffiles_dQ,
         cup_id_and_rate_file_name,
         qr_file_name,
         qs_file_name,
         output_summary_file_name
         ):
    """ Main program. """
    #cup_id_and_rate_file_name = 'cup_id_and_rate.csv'
    station_number_and_names_file_name = os.path.join(postproc_deffiles_dQ,'station_number_and_names.csv')
    upstream_gage_numbers_file_name = os.path.join(postproc_deffiles_dQ,'upstream_gage_numbers.csv')
    #qr_file_name = 'gaged_reach_fluxes.asc'
    #qs_file_name = 'gaged_fluxes_sum.csv'
    #output_summary_file_name = 'delta_q_summary.csv'
    
    a = ContributingGages()
    a.read_file_with_cup_id_and_amount(cup_id_and_rate_file_name)
    a.initialize_output_files(output_summary_file_name)
    a.parse_station_numbers_and_names_file(station_number_and_names_file_name)
    a.parse_simualted_qr_file(qr_file_name)
    a.parse_simualted_qs_file(qs_file_name)
    a.output_station_fluxes()
    a.close_output_files()
    
    currentmessage = ('Done with delta_q_report!\n\n')
    print (currentmessage)
    with open(logfile,'a') as lf: lf.write(currentmessage)
    
#main()
